\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{parskip}

\hypersetup{colorlinks=true, linkcolor=blue}
\lstset{basicstyle=\ttfamily\small, breaklines=true}

\title{Jal Sarovar: ML-Driven Water Quality Monitoring}
\author{}
\date{}

\begin{document}
\maketitle

\begin{abstract}
This research presents a comprehensive machine learning framework for water quality monitoring in India,
            addressing critical limitations of traditional laboratory testing through a dual-scale monitoring paradigm.
            At the public scale , the LEGOLAS autonomous robotic platform surveys geographically
            distributed water bodies (stepwells, tanks, ponds, rivers) with multi-parameter sensors (pH, TDS, turbidity,
            dissolved oxygen, temperature) and computer vision capabilities for population-level surveillance.
            At the residential scale , low-cost IoT sensors (₹8,000-15,000 per household) provide
            continuous real-time monitoring with 15-minute sampling intervals for immediate contamination alerts. The system integrates five production-ready machine learning models trained on a comprehensive dataset
            of [TOTAL\textbackslash \_SAMPLES] water samples from [TOTAL\textbackslash \_SITES] monitoring sites spanning
            [DATE\textbackslash \_RANGE] years. Models achieve 84.6\% accuracy for site risk classification , 73.4\% for contamination type detection , and R²=0.94 for time-series forecasting ,
            while demonstrating [COST\textbackslash \_REDUCTION]\% cost reduction through intelligent
            resource allocation compared to traditional exhaustive testing. A unique hybrid data architecture enables coexistence of manual data collection (CSV uploads, API integration,
            laboratory submissions) with autonomous sensor streams (LEGOLAS measurements, IoT readings), weighted by
            reliability for decision-making. The framework supports multiple government initiatives including Mission Amrit Sarovar (68,000+ water bodies nationally), Jal Jeevan Mission (rural drinking water safety), and state/municipal water quality programs. Following successful proof-of-concept deployment and ML model validation, the system is currently scaling
            autonomous monitoring infrastructure while maintaining continuous bulk data import from existing monitoring
            networks. This incremental transition preserves human expertise and laboratory validation as essential
            components of water safety decision-making.
\end{abstract}

\tableofcontents
\newpage

Machine Learning Framework Trained on Bulk Imported Data with Phased LEGOLAS Robotic and IoT Sensor Deployment

\section{Introduction}\label{section-1}

\subsection{Motivation and Project Objectives}\label{section-1-1}

Safe drinking water is fundamental to human health, yet approximately 2 billion people globally lack access to safely
        managed drinking water services. In India alone, water contamination contributes to 37.7 million cases of waterborne
        diseases annually. Traditional water quality monitoring approaches face critical limitations: high cost (estimated Rs. 1,000-2,000
        per laboratory sample), delayed detection (monthly/quarterly testing misses rapid contamination events), and limited
        coverage preventing comprehensive monitoring of all water sources.

Jal Sarovar addresses these challenges by supporting the goals of various Government initiatives in India
        at both State and Central levels, including:

\begin{itemize}
\item Mission Amrit Sarovar: Supporting the development and rejuvenation of 75 water bodies in each district (approximately 68,000 water bodies nationwide)
\item Jal Jeevan Mission: Enabling water quality monitoring for safe and adequate drinking water to rural households
\item Municipal Administration and Urban Development Departments: Providing data-driven insights for urban water body management at State and Central levels
\item Water Supply and Drainage Boards: Supporting continuous monitoring and quality assurance for public water supply infrastructure
\end{itemize}

Beyond supporting these national and state-level initiatives, the project establishes a framework for nationwide
        collaboration for tracking water quality in both public water bodies and private sites, enabling
        comprehensive monitoring at multiple scales and supporting evidence-based policy decisions with a truly national and global collaborative approach based on sharing of water quality parameters across regions.

\subsection{The Dual-Scale Paradigm}\label{section-1-2}

Water quality management inherently operates at two distinct scales, each serving complementary purposes:

\begin{itemize}
\item Geographically distributed public water bodies (rivers, stepwells, tanks, ponds)
\item Periodic testing via LEGOLAS autonomous robots (weekly to quarterly)
\item Population-level surveillance and policy decisions
\item Cost-optimized resource allocation
\end{itemize}

\begin{itemize}
\item Commercial and Residential communities
\item Continuous real-time monitoring (15-60 minute intervals)
\item Water safety assurance and immediate alerts
\item Consumer-grade affordability
\end{itemize}

These scales are complementary: public site monitoring identifies systemic contamination patterns and informs
        policy interventions, while private site monitoring provides granular safety verification and empowers
        institutions and individuals. This proof-of-concept validates the first integrated system combining both scales with coordinated
        ML analytics, supporting multiple initiatives' goals of comprehensive water body rejuvenation and establishing a
        model for national and global water quality collaboration.

\subsection{ML-Driven Capabilities}\label{section-1-3}

Jal Sarovar provides a comprehensive ML pipeline with the following capabilities:

\begin{itemize}
\item Bulk Data Import \& Processing: CSV uploads, API integration, and mobile app submissions from NABL/ISO 17025 accredited laboratory test results
\item 5 Production-Ready ML Models: Site Risk Classifier (84.6\% accuracy), Contamination Classifier (73.4\% accuracy), Water Quality Forecaster (R²=0.94), Bayesian Cost Optimizer, and Hybrid Anomaly Detector
\item LEGOLAS Autonomous Robotic Testing: Multi-parameter water quality sensors with computer vision for algae detection deployed on public water bodies
\item IoT Real-Time Monitoring: Low-cost inline sensors (₹8,000-15,000) for continuous household water quality monitoring with 15-minute sampling intervals
\item Hybrid Data Architecture: Multi-source data fusion combining manual laboratory testing with autonomous sensor streams, weighted by reliability (laboratory > LEGOLAS > IoT)
\end{itemize}

See Section 12.1 Implementation Roadmap for detailed phased deployment timeline.

\subsection{Implementation Phases}\label{section-1-4}

The Jal Sarovar framework development follows a six-phase incremental approach, progressing from
        foundational infrastructure to long-term hybrid operations. A detailed Implementation Roadmap with status, milestones, and timelines is provided in Section 12.1 .

See Section 12.1 Implementation Roadmap for complete phase details,
        technical specifications, and timelines.

\section{System Overview}\label{section-2}

\subsection{Data Sources and Collection Methodology}\label{section-2-0}

\subsubsection{Data Collection Sources}

The Jal Sarovar system operates on a hybrid data collection model combining multiple sources. Bulk imported laboratory test results from [TOTAL\textbackslash \_SITES] public monitoring sites serve
        as the primary data foundation, supplemented by autonomous monitoring from LEGOLAS robotic platforms and IoT sensor
        networks. This comprehensive dataset spans [DATE\textbackslash \_RANGE] years ([MIN\textbackslash \_DATE] to [MAX\textbackslash \_DATE])
        and includes [TOTAL\textbackslash \_SAMPLES] water samples with [TOTAL\textbackslash \_TESTS] parameter measurements.

\subsubsection{Data Import Methods}

{\small
\begin{longtable}{|p{2.5cm}|p{3cm}|p{3cm}|p{3.5cm}|p{2cm}|}
\hline
\textbf{Method} & \textbf{Source} & \textbf{Frequency} & \textbf{Parameters} & \textbf{Status} \\
\hline
CSV Upload (Bulk Import) & Government agencies, research institutions, NGOs & Batch imports (daily/weekly/monthly/quarterly) & Full 45-parameter test results from accredited labs & Primary Source \\
\hline
API Integration & Partner laboratories, government databases & Daily/Weekly sync & Standardized JSON format with WHO/BIS validation & Active \\
\hline
Manual Entry & Field teams, community volunteers & On-demand & Field test kits (pH, turbidity, TDS, chlorine, coliform) & Active \\
\hline
Mobile App & Field operators (manual sampling for lab analysis) & Site visits & GPS-tagged sample collection sent to laboratories & Scaling Up \\
\hline
LEGOLAS Autonomous Robot & Autonomous robotic platform on public water bodies & Continuous autonomous monitoring & Multi-sensor (pH, turbidity, DO, temperature, conductivity) & Scaling Up \\
\hline
IoT Sensors & Inline sensors on residential water systems & Real-time monitoring (15-min intervals) & pH, turbidity, TDS, chlorine, temperature & Scaling Up \\
\hline
\end{longtable}
}

\subsubsection{Data Quality and Validation}

\begin{itemize}
\item Laboratory Accreditation: All samples tested by NABL/ISO 17025 certified laboratories What is NABL/ISO 17025? NABL (National Accreditation Board for Testing and Calibration Laboratories): India's premier accreditation body established by the Government of India. NABL accreditation ensures
                        that testing laboratories meet internationally recognized standards for technical competence, quality management,
                        and reliable testing practices. NABL operates under the Department of Science and Technology. ISO/IEC 17025: International standard titled "General requirements for the competence
                        of testing and calibration laboratories." This standard specifies requirements for: Technical competence of laboratory personnel Validity and reliability of test results Quality management systems Proper equipment calibration and maintenance Traceability of measurements to international standards Examples of NABL-accredited water testing laboratories in India: State Public Health Engineering Departments (PHED) laboratories Central Pollution Control Board (CPCB) regional laboratories State Pollution Control Board (SPCB) laboratories Indian Institute of Technology (IIT) environmental testing labs National Institute of Hydrology (NIH) laboratories Private NABL-accredited laboratories (e.g., Eurofins, SGS India, TÜV SÜD) Municipal corporation water quality testing facilities Why NABL/ISO 17025 certification matters: Ensures that water quality test results
                        are accurate, reproducible, and legally defensible. Government agencies, courts, and regulatory bodies
                        accept test reports only from NABL/ISO 17025 accredited laboratories for compliance verification,
                        legal proceedings, and policy decisions.
\item Parameter Standardization: Measurements converted to WHO/BIS standard units (mg/L, NTU, MPN/100mL)
\item Outlier Detection: Statistical validation removes measurement errors and sensor malfunctions
\item Geospatial Validation: GPS coordinates verified against known water body locations
\item Temporal Consistency: Time series analysis flags unrealistic parameter changes
\end{itemize}

\begin{itemize}
\item NABL (National Accreditation Board for Testing and Calibration Laboratories): India's premier accreditation body established by the Government of India. NABL accreditation ensures
                        that testing laboratories meet internationally recognized standards for technical competence, quality management,
                        and reliable testing practices. NABL operates under the Department of Science and Technology.
\item ISO/IEC 17025: International standard titled "General requirements for the competence
                        of testing and calibration laboratories." This standard specifies requirements for: Technical competence of laboratory personnel Validity and reliability of test results Quality management systems Proper equipment calibration and maintenance Traceability of measurements to international standards
\item Examples of NABL-accredited water testing laboratories in India: State Public Health Engineering Departments (PHED) laboratories Central Pollution Control Board (CPCB) regional laboratories State Pollution Control Board (SPCB) laboratories Indian Institute of Technology (IIT) environmental testing labs National Institute of Hydrology (NIH) laboratories Private NABL-accredited laboratories (e.g., Eurofins, SGS India, TÜV SÜD) Municipal corporation water quality testing facilities
\item Why NABL/ISO 17025 certification matters: Ensures that water quality test results
                        are accurate, reproducible, and legally defensible. Government agencies, courts, and regulatory bodies
                        accept test reports only from NABL/ISO 17025 accredited laboratories for compliance verification,
                        legal proceedings, and policy decisions.
\end{itemize}

\begin{itemize}
\item Technical competence of laboratory personnel
\item Validity and reliability of test results
\item Quality management systems
\item Proper equipment calibration and maintenance
\item Traceability of measurements to international standards
\end{itemize}

\begin{itemize}
\item State Public Health Engineering Departments (PHED) laboratories
\item Central Pollution Control Board (CPCB) regional laboratories
\item State Pollution Control Board (SPCB) laboratories
\item Indian Institute of Technology (IIT) environmental testing labs
\item National Institute of Hydrology (NIH) laboratories
\item Private NABL-accredited laboratories (e.g., Eurofins, SGS India, TÜV SÜD)
\item Municipal corporation water quality testing facilities
\end{itemize}

\subsubsection{Role of Data in System Intelligence}

Bulk imported historical data serves as the primary training foundation for all ML models,
        supplemented by preliminary trial data from LEGOLAS and IoT systems (Phase 1).
        The 20,269+ labeled samples enable the system to:

\begin{itemize}
\item Learn contamination risk patterns across different site types and geographic regions
\item Recognize chemical signatures of specific contamination sources (sewage, runoff, corrosion)
\item Forecast seasonal water quality trends and predict threshold violations
\item Optimize resource allocation by understanding detection-cost tradeoffs
\item Detect both sudden anomalies and gradual drift in water quality parameters
\end{itemize}

All 5 production-ready ML models are operational , trained on bulk imported historical laboratory data
        supplemented by autonomous sensor measurements from LEGOLAS robots and IoT networks. The system continues to import
        existing laboratory samples while integrating real-time autonomous sensor data for production predictions. The hybrid
        operational model balances high-reliability laboratory testing with high-frequency autonomous monitoring, weighted by
        data source reliability (laboratory > LEGOLAS > IoT) for decision-making.

See Section 12.1 Implementation Roadmap for detailed deployment timeline and scaling strategy.

\subsection{LEGOLAS: Autonomous Robotic Architecture}\label{section-2-1}

LEGOLAS is a low-cost autonomous water quality assessment platform for continuous monitoring of
        public water bodies (stepwells, tanks, ponds, rivers). The platform integrates multi-parameter sensors with computer
        vision capabilities and GPS navigation, providing real-time data to production ML models for site risk assessment,
        contamination detection, and water quality forecasting.

\begin{itemize}
\item Raspberry Pi based System
\item Fiberglass hull (1.2m × 0.8m × 0.4m)
\item Dual brushless DC motors (300W each)
\item GPS navigation (2.5m accuracy)
\item 4G LTE real-time data upload
\item Solar charging (14-day autonomy)
\end{itemize}

\begin{itemize}
\item pH sensor (±0.1 accuracy)
\item TDS probe (±2\% accuracy)
\item Turbidity sensor (0.1-1000 NTU)
\item Dissolved oxygen (±5\%)
\item Temperature (±0.5°C)
\item 5MP RGB camera for imaging
\end{itemize}

Cost Analysis: LEGOLAS reduces estimated per-test cost to Rs. 540 (amortized over
        3-year lifespan with 2 tests/week), a 73\% reduction compared to manual sampling (estimated Rs. 2,000/test
        including transport and labor).

\subsubsection{Computer Vision for Algae Detection}

LEGOLAS integrates a MobileNetV2-based computer vision pipeline for algae classification
        from RGB surface images. The system performs 4-class classification: No algae (clear water), Green algae
        (Chlorophyta), Cyanobacteria (blue-green, toxic), and Diatoms (brown/golden algae).

\begin{longtable}{|l|l|l|l|l|}
\hline
Algae Class & Precision & Recall & F1-Score & Samples \\
\hline
No algae (clear water) & 0.91 & 0.93 & 0.92 & 462 \\
\hline
Green algae (Chlorophyta) & 0.84 & 0.82 & 0.83 & 122 \\
\hline
Cyanobacteria (toxic) & 0.88 & 0.85 & 0.86 & 75 \\
\hline
Diatoms (brown/golden) & 0.79 & 0.75 & 0.77 & 20 \\
\hline
Weighted Average & 0.88 & 0.87 & 0.87 & 679 \\
\hline
\end{longtable}

Bacterial Contamination Estimation: Multi-modal regression combining turbidity,
        color intensity, and dissolved oxygen achieves R²=0.79 correlation with laboratory coliform tests (Pearson r=0.89, p<0.001), enabling instant bacterial safety alerts without 24-48 hour laboratory delays.

\subsection{IoT Sensor Architecture}\label{section-2-2}

The IoT sensor network provides continuous real-time water quality monitoring for residential and small-scale
        water systems. Low-cost inline sensors (₹8,000-15,000 per installation) measure key parameters at 15-minute
        intervals, enabling immediate contamination alerts and real-time anomaly detection through integrated ML models.
        This architecture is designed for large-scale deployment across households and community water distribution systems.

\begin{itemize}
\item Raspberry Pi or equivalent Microcontroller Based System
\item pH sensor
\item TDS sensor
\item Turbidity sensor
\item Temperature sensor
\item Chlorine sensor
\item IP65-rated enclosure
\end{itemize}

\begin{itemize}
\item Sampling: 15-minute intervals (configurable 5-60 min)
\item Averaging: 3 measurements per cycle
\item Outlier rejection for data quality
\item Automated 2-point calibration every 7 days
\item 12-hour battery backup during power outages
\end{itemize}

\begin{itemize}
\item Edge Computing: On-device WQI calculation (sub-100ms)
\item Cloud sync via MQTT
\item Time-series storage (InfluxDB, 90-day retention)
\item SMS/push notifications via SNS (sub-5-second latency)
\end{itemize}

Deployment Scope: The framework demonstrates viability for nationwide expansion supporting the
        multiple water supply initiatives and enabling global water quality collaboration across diverse regional water quality
        characteristics and environmental patterns.

\subsection{Data Summary}\label{section-2-3}

\subsubsection{Total Sites}

\subsubsection{Water Samples}

\subsubsection{Date Range}

\subsubsection{Samples/Site}

\begin{longtable}{|l|l|l|}
\hline
Metric & Value & Details \\
\hline
Sites Monitored & [TOTAL\_SITES] & [STATES] \\
\hline
Water Samples & [TOTAL\_SAMPLES] & [MIN\_DATE] to [MAX\_DATE] \\
\hline
Test Results & [TOTAL\_TESTS] & \textasciitilde [AVG\textbackslash \_SAMPLES] samples per site \\
\hline
Site Risk Predictions & [RISK\_PRED] & Critical: [RISK\textbackslash \_CRIT], High: [RISK\textbackslash \_HIGH], Medium: [RISK\textbackslash \_MED], Low: [RISK\textbackslash \_LOW] \\
\hline
Contamination Predictions & [DATA] & [DATA] \\
\hline
WQI Readings & [DATA] & Avg: [DATA], Classes: [DATA] \\
\hline
Water Quality Forecasts & [DATA] & R²=[DATA] for pH, TDS, turbidity, temperature \\
\hline
Cost Optimization Results & [DATA] & [COST\textbackslash \_REDUCTION]\% avg reduction, [DATA]\% detection \\
\hline
\end{longtable}

\subsection{Water Quality Parameters}\label{section-2-4}

The Jal Sarovar system measures a comprehensive set of 40+ water quality parameters across physical,
        chemical, and microbiological categories. These parameters are captured in laboratory test results and analyzed by
        the ML pipeline to assess water safety and contamination patterns.

\begin{longtable}{|l|l|l|l|}
\hline
Category & Parameter & Unit & Description \\
\hline
Physical Parameters & pH & - & Acidity/alkalinity measure (optimal: 6.5-8.5) \\
\hline
Temperature & °C & Water temperature in Celsius &  \\
\hline
Turbidity & NTU & Cloudiness or haziness (threshold: <5 NTU) &  \\
\hline
Color & Hazen & Water color intensity &  \\
\hline
Odor & 1-5 scale & Odor threshold rating &  \\
\hline
Taste & 1-5 scale & Taste quality rating &  \\
\hline
Conductivity & µS/cm & Electrical conductivity (microsiemens per centimeter) &  \\
\hline
Chemical - General & TDS (Total Dissolved Solids) & ppm & Total dissolved mineral content (threshold: <500 ppm) \\
\hline
Total Hardness & mg/L & Calcium and magnesium concentration &  \\
\hline
Calcium Hardness & mg/L & Calcium-specific hardness &  \\
\hline
Magnesium Hardness & mg/L & Magnesium-specific hardness &  \\
\hline
Total Alkalinity & mg/L & Buffer capacity against pH changes &  \\
\hline
Disinfection & Free Chlorine & mg/L & Available chlorine for disinfection (optimal: 0.2-5.0 mg/L) \\
\hline
Total Chlorine & mg/L & Combined free and bound chlorine &  \\
\hline
Chlorine Residual & mg/L & Residual chlorine after reaction &  \\
\hline
Anions & Chloride & mg/L & Chloride ion concentration (threshold: <250 mg/L) \\
\hline
Fluoride & mg/L & Fluoride content (optimal: 0.5-1.5 mg/L) &  \\
\hline
Sulfate & mg/L & Sulfate concentration &  \\
\hline
Nitrate & mg/L & Nitrate-nitrogen (threshold: <50 mg/L) &  \\
\hline
Nitrite & mg/L & Nitrite-nitrogen concentration &  \\
\hline
Phosphate & mg/L & Phosphate concentration &  \\
\hline
Cations / Metals & Iron & mg/L & Iron content (threshold: <0.3 mg/L) \\
\hline
Manganese & mg/L & Manganese concentration (threshold: <0.1 mg/L) &  \\
\hline
Copper & mg/L & Copper content &  \\
\hline
Zinc & mg/L & Zinc concentration &  \\
\hline
Lead & mg/L & Lead content (threshold: <0.01 mg/L) &  \\
\hline
Arsenic & mg/L & Arsenic concentration (threshold: <0.01 mg/L) &  \\
\hline
Chromium & mg/L & Chromium content &  \\
\hline
Cadmium & mg/L & Cadmium concentration (threshold: <0.003 mg/L) &  \\
\hline
Mercury & mg/L & Mercury content (threshold: <0.001 mg/L) &  \\
\hline
Nickel & mg/L & Nickel concentration &  \\
\hline
Aluminum & mg/L & Aluminum content &  \\
\hline
Sodium & mg/L & Sodium ion concentration &  \\
\hline
Potassium & mg/L & Potassium content &  \\
\hline
Nitrogen Compounds & Ammonia & mg/L & Ammonia-nitrogen (threshold: <0.5 mg/L) \\
\hline
Total Nitrogen & mg/L & All forms of nitrogen &  \\
\hline
Organic Nitrogen & mg/L & Nitrogen in organic compounds &  \\
\hline
Organic Parameters & Dissolved Oxygen (DO) & mg/L & Oxygen dissolved in water \\
\hline
BOD (Biochemical Oxygen Demand) & mg/L & Oxygen required by bacteria to decompose organic matter &  \\
\hline
COD (Chemical Oxygen Demand) & mg/L & Oxygen required to chemically oxidize organic matter &  \\
\hline
TOC (Total Organic Carbon) & mg/L & Total organic carbon content &  \\
\hline
Microbiological & Total Coliform & MPN/100mL & Total coliform bacteria (should be 0 for drinking water) \\
\hline
Fecal Coliform & MPN/100mL & Fecal contamination indicator &  \\
\hline
E. coli & MPN/100mL & Escherichia coli presence (should be 0) &  \\
\hline
Total Plate Count & CFU/mL & Total viable bacteria count (colony forming units) &  \\
\hline
Pesticides/Herbicides & Pesticides Detected & Boolean & Presence/absence of pesticides \\
\hline
Pesticide Types & List & Specific pesticides identified &  \\
\hline
\end{longtable}

Parameter Coverage Assessment: The system evaluates data quality based on parameter coverage. Full assessment requires ≥3 key parameters; partial assessment requires ≥1 key parameter; insufficient data indicates no key parameters measured. This tiered approach ensures ML predictions
        are only generated when sufficient data quality is available.

\subsection{ML Pipeline Architecture}\label{section-2-2-ml}

\subsubsection{Machine Learning Models (5 Total - Data-Driven Algorithms)}

The following models use machine learning algorithms that learn from data and optimize their behavior.

\begin{itemize}
\item Site Risk Classifier: Random Forest (ensemble of decision trees for classification)
\item Contamination Classifier: XGBoost (gradient boosted trees for multi-class classification)
\item Water Quality Forecaster: Gaussian Process (Bayesian non-parametric regression with uncertainty quantification)
\item Bayesian Cost Optimizer: Bayesian Optimization (GP-based black-box optimization with Expected Improvement)
\item Hybrid Anomaly Detector: Isolation Forest + CUSUM (unsupervised anomaly detection with drift detection)
\end{itemize}

\subsubsection{Deterministic Algorithm (Rule-Based - NOT Machine Learning)}

The following is NOT machine learning . It uses fixed formulas and thresholds defined by WHO/BIS standards. Same inputs always produce the same output.

\begin{itemize}
\item Real-time WQI Calculator: Penalty-based scoring using WHO/BIS water quality standards (deterministic calculation)
\end{itemize}

\section{Site Risk Classifier (Random Forest)}\label{section-3}

Purpose: Predict contamination risk level for water bodies to prioritize testing resources.

Algorithm: Random Forest with feature engineering from site characteristics and historical data.

\subsection{How It Functions}\label{section-3-0}

\subsubsection{Why Random Forest?}

Random Forest was chosen for site risk classification because water contamination depends on complex interactions between multiple environmental factors. Unlike a single decision tree that might miss subtle patterns, Random Forest builds 100 independent trees, each learning from different data perspectives. This "wisdom of the crowd" approach handles the complexity of real-world contamination scenarios where industrial proximity might matter more for coastal sites than for inland agricultural areas.

Think of training as teaching 100 different experts to recognize contamination risk. Each expert (decision tree) looks at the same historical data but focuses on different aspects. One expert might learn: "If a stepwell is near industry AND hasn't been tested in 60+ days, it's high risk." Another learns: "Coastal urban sites with 20\%+ contamination history are critical." During training on 20,269 historical site assessments, the forest discovers that recent contamination history (42\% importance) and testing recency (23\% importance) are the strongest signals.

\subsubsection{Prediction Workflow}

When evaluating a new site, each of the 100 trees votes for a risk category (critical, high, medium, or low). The forest counts votes: if 73 trees vote "high risk" and 27 vote "medium risk," the site is classified as "high" with 73\% confidence. The model then recommends bi-weekly testing (26 tests/year) for high-risk sites based on learned associations between risk levels and optimal monitoring frequencies.

\subsubsection{Real-World Example}

A stepwell near an industrial zone in Gujarat with 35\% historical contamination rate and 45 days since last test would trigger majority votes for "high risk" because the model learned this combination often precedes contamination events. The system recommends bi-weekly testing (26 tests/year) to catch problems before they spread.

\subsubsection{When Invoked}

This model runs during testing schedule optimization to assign monitoring frequencies across all sites in the network.

\subsection{Input Parameters}\label{section-3-1}

\begin{longtable}{|l|l|l|l|}
\hline
Parameter & Type & Description & Example \\
\hline
site\_type & string & Type of water body & "stepwell", "tank", "pond", "lake" \\
\hline
is\_industrial\_nearby & boolean & Industrial facilities within 5km & true/false \\
\hline
is\_agricultural\_nearby & boolean & Agricultural land within 2km & true/false \\
\hline
is\_coastal & boolean & Within 10km of coastline & true/false \\
\hline
is\_urban & boolean & Urban population density >500/km² & true/false \\
\hline
contamination\_rate\_30d & float & Historical contamination \% (30 days) & 0-100 \\
\hline
days\_since\_last\_test & int & Days since last water test & 0-365 \\
\hline
\end{longtable}

\subsection{Machine Learning Algorithm Details}\label{section-3-2}

Implementation: sklearn.ensemble.RandomForestClassifier

Training Data: 20,269 labeled samples from historical site assessments

\subsubsection{Hyperparameters}

\begin{itemize}
\item n\_estimators: 100 decision trees in the ensemble
\item max\_depth: 8 levels per tree
\item min\_samples\_split: 10 samples required to split a node
\item class\_weight: 'balanced' (handles class imbalance)
\item random\_state: 42 (for reproducibility)
\end{itemize}

\subsubsection{Feature Engineering}

\begin{itemize}
\item One-hot encoding for site\_type (4 binary features)
\item Boolean to binary: Environmental factors (0/1)
\item Numerical features: contamination\_rate\_30d, days\_since\_last\_test
\item Total features: 10 input dimensions
\end{itemize}

\subsubsection{Training Process}

\begin{enumerate}
\item Split data: 80\% training, 20\% validation
\item Build 100 decision trees on random subsamples
\item Each tree learns different decision boundaries
\item Ensemble aggregation: majority voting across all trees
\item Calculate class probabilities from vote percentages
\end{enumerate}

\subsubsection{Model Performance}

\begin{itemize}
\item Training Accuracy: 87.3\%
\item Validation Accuracy: 84.6\%
\item F1 Score: 0.835
\end{itemize}

\subsubsection{Feature Importance (Learned from Data)}

\begin{longtable}{|l|l|l|}
\hline
Feature & Importance & Interpretation \\
\hline
contamination\_rate\_30d & 0.42 & Strongest predictor \\
\hline
days\_since\_last\_test & 0.23 & Testing recency matters \\
\hline
is\_industrial\_nearby & 0.15 & Industrial proximity risk \\
\hline
site\_type\_stepwell & 0.12 & Site-specific patterns \\
\hline
is\_urban & 0.08 & Urban contamination signal \\
\hline
\end{longtable}

\subsection{Output Parameters}\label{section-3-3}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
risk\_level & string & "critical", "high", "medium", "low" \\
\hline
risk\_score & float & 0-100 numerical score \\
\hline
confidence & float & Model confidence percentage \\
\hline
recommended\_frequency & string & "weekly", "bi-weekly", "monthly", "quarterly" \\
\hline
tests\_per\_year & int & Recommended annual tests (52, 26, 12, or 4) \\
\hline
\end{longtable}

\subsection{Pseudocode}\label{section-3-4}

\section{Contamination Classifier (XGBoost)}\label{section-4}

Purpose: Classify contamination source type to guide remediation strategies.

Algorithm: XGBoost multi-class classifier with probability outputs.

\subsection{How It Functions}\label{section-4-0}

\subsubsection{Why Gradient Boosting?}

XGBoost was selected for contamination classification because different pollution sources create overlapping chemical signatures that require progressive refinement. Sewage might elevate both coliform and ammonia, while pipe corrosion raises iron and manganese but not bacteria. Gradient boosting excels at these nuanced distinctions by building trees sequentially, where each new tree focuses on correcting the mistakes of previous trees—learning the subtle differences between contamination types.

Imagine 100 increasingly specialized detectives investigating contamination. The first detective makes broad guesses: "High coliform = sewage." But this misses some cases. The second detective studies the first's errors: "High coliform WITHOUT elevated ammonia = agricultural runoff, not sewage." Each subsequent detective (tree) becomes an expert in the remaining confusing cases. By tree 100, the ensemble achieves 78.9\% training accuracy on 20,508 labeled samples, with total\_coliform (28\% importance), turbidity (19\%), and free\_chlorine (17\%) emerging as the strongest discriminators.

\subsubsection{Prediction Workflow}

For a new water sample, all 100 trees vote with weighted scores. Each tree applies learned decision rules like "if coliform > 15 AND ammonia > 0.8 → sewage\_ingress (0.42 probability)." The final prediction aggregates these weighted votes through softmax conversion: sewage\_ingress (65\%), pipe\_corrosion (22\%), runoff\_sediment (8\%), others (5\%). The model returns the top prediction (sewage) with 65\% confidence.

\subsubsection{Real-World Example}

A residential water sample shows high turbidity (12 NTU), elevated coliform (25 MPN/100mL), high ammonia (1.2 mg/L), but normal iron levels. The model distinguishes this as sewage contamination (not pipe corrosion) because the ammonia-coliform combination without metallic signatures matches learned sewage patterns. This guides operators to inspect sewer lines rather than water pipes.

\subsubsection{When Invoked}

This model runs immediately after contamination detection (when WQI falls below thresholds) to identify the pollution source and guide targeted remediation.

\subsection{Input Parameters}\label{section-4-1}

\begin{longtable}{|l|l|l|l|}
\hline
Parameter & Type & Unit & WHO/BIS Threshold \\
\hline
ph & float & - & 6.5-8.5 \\
\hline
turbidity & float & NTU & <5 \\
\hline
tds & float & ppm & <500 \\
\hline
chlorine & float & mg/L & 0.2-5.0 \\
\hline
iron & float & mg/L & <0.3 \\
\hline
manganese & float & mg/L & <0.4 \\
\hline
coliform & float & MPN/100mL & 0 \\
\hline
ammonia & float & mg/L & <0.5 \\
\hline
chloride & float & mg/L & <250 \\
\hline
\end{longtable}

\subsection{Machine Learning Algorithm Details}\label{section-4-2}

Implementation: xgboost.XGBClassifier

Training Data: 20,508 labeled contamination samples

\subsubsection{Hyperparameters}

\begin{itemize}
\item n\_estimators: 100 boosted trees
\item max\_depth: 6 levels per tree
\item learning\_rate: 0.1 (eta parameter)
\item subsample: 0.8 (80\% data per tree)
\item colsample\_bytree: 0.8 (80\% features per tree)
\item objective: 'multi:softprob' (multi-class probabilities)
\end{itemize}

\subsubsection{Feature Engineering}

\begin{itemize}
\item Water quality parameters (9 features): pH, turbidity, TDS, free\_chlorine, iron, manganese, total\_coliform, ammonia, chloride
\item Environmental context (2 features): rained\_recently, is\_coastal
\item Feature scaling: StandardScaler normalization (mean=0, std=1)
\item Total features: 11 input dimensions
\end{itemize}

\subsubsection{Training Process}

\begin{enumerate}
\item Encode contamination types to integers (0-7)
\item Gradient boosting iteration: Fit each tree to residual errors of previous trees Each tree corrects ensemble mistakes Apply learning\_rate to prevent overfitting Use subsample for randomness
\item Ensemble prediction: weighted sum of all 100 tree predictions
\item Softmax conversion to probabilities
\end{enumerate}

\begin{itemize}
\item Fit each tree to residual errors of previous trees
\item Each tree corrects ensemble mistakes
\item Apply learning\_rate to prevent overfitting
\item Use subsample for randomness
\end{itemize}

\subsubsection{Model Performance}

\begin{itemize}
\item Training Accuracy: 78.9\%
\item Validation Accuracy: 73.4\%
\item Macro F1 Score: 0.68
\item Best Detected: sewage\_ingress (F1: 0.82)
\end{itemize}

\subsubsection{Feature Importance (Learned via Gain)}

\begin{longtable}{|l|l|}
\hline
Feature & Importance \\
\hline
total\_coliform & 0.28 \\
\hline
turbidity & 0.19 \\
\hline
free\_chlorine & 0.17 \\
\hline
TDS & 0.12 \\
\hline
ammonia & 0.10 \\
\hline
chloride & 0.08 \\
\hline
pH & 0.06 \\
\hline
\end{longtable}

\subsection{Output Parameters}\label{section-4-3}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
predicted\_type & string & Contamination source type \\
\hline
confidence & float & Probability × 100 \\
\hline
prob\_runoff\_sediment & float & 0-1 probability \\
\hline
prob\_sewage\_ingress & float & 0-1 probability \\
\hline
prob\_salt\_intrusion & float & 0-1 probability \\
\hline
prob\_pipe\_corrosion & float & 0-1 probability \\
\hline
prob\_disinfectant\_decay & float & 0-1 probability \\
\hline
\end{longtable}

\subsection{Pseudocode}\label{section-4-4}

\section{Water Quality Forecaster (Gaussian Process)}\label{section-5}

Purpose: Predict future water quality parameter values with uncertainty bounds.

Algorithm: Gaussian Process regression with trend and seasonality components.

\subsection{How It Functions}\label{section-5-0}

\subsubsection{Why Gaussian Process Instead of Linear Regression?}

Water quality doesn't follow simple straight-line trends—pH might spike after monsoons, TDS increases gradually from salt intrusion, and turbidity shows seasonal patterns. Gaussian Processes (GP) excel here because they're non-parametric : instead of forcing data into a predetermined equation, GP learns the underlying pattern's shape from data. Crucially, GP provides Bayesian uncertainty quantification , telling operators "pH will be 7.2 ± 0.3" rather than just "7.2"—critical for proactive intervention planning.

Think of Gaussian Processes as drawing a "cloud of possible futures" based on historical patterns. The model learns a similarity function (kernel): measurements close in time should have similar values. Training on historical time series [(Jan 1: pH 7.4), (Jan 15: pH 7.3), (Feb 1: pH 7.1)...], the GP discovers that pH typically changes smoothly over \textasciitilde 30-day periods (the learned length scale). The RBF kernel captures this: recent data points influence predictions more than distant ones, creating smooth, realistic forecasts.

\subsubsection{Prediction Workflow}

To forecast 90 days ahead, the GP computes similarity between the target date and all historical observations. It asks: "This future date is 45 days from our last reading—what did pH typically do after 45-day gaps historically?" The model outputs a probability distribution: mean prediction (most likely value) plus confidence bounds. For example: "30 days ahead, pH will be 7.3 ± 0.15 (95\% confidence)" where uncertainty widens for distant predictions (90 days: ± 0.42).

\subsubsection{Real-World Example}

A coastal site shows TDS gradually increasing from 380 ppm (January) to 450 ppm (March). The GP forecast predicts TDS will reach 520 ppm by June (exceeding the 500 ppm threshold) with 82\% confidence. This triggers proactive desalination planning rather than waiting for reactive contamination alerts—preventing 3 months of unsafe water.

\subsubsection{When Invoked}

This model runs weekly for monitored sites with sufficient historical data (minimum 10 samples) to generate 90-day forecasts for pH, TDS, and turbidity.

\subsection{Input Parameters}\label{section-5-1}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
site\_id & int & Unique site identifier \\
\hline
parameter & string & "ph", "turbidity", "tds", "chlorine", "temperature" \\
\hline
historical\_data & array & List of \{date, value\} pairs (minimum 10 samples) \\
\hline
days\_ahead & int & Forecast horizon (default: 90 days) \\
\hline
\end{longtable}

\subsection{Machine Learning Algorithm Details}\label{section-5-2}

Implementation: sklearn.gaussian\_process.GaussianProcessRegressor

Approach: Non-parametric Bayesian regression on time series

\subsubsection{Kernel Function}

RBF (Radial Basis Function) + White Noise:

\begin{itemize}
\item Formula: k(x, x') = σ²\_signal × exp(-||x - x'||² / (2 × l²)) + σ²\_noise × δ(x, x')
\item σ²\_signal: Signal variance (learned from data)
\item l: Length scale - determines smoothness (30 days)
\item σ²\_noise: Noise variance - measurement uncertainty (0.1)
\end{itemize}

\subsubsection{Hyperparameters}

\begin{itemize}
\item Kernel: RBF(length\_scale=30) + WhiteKernel(noise\_level=0.1)
\item n\_restarts\_optimizer: 10 (avoid local optima)
\item alpha: 1e-10 (numerical stability)
\item normalize\_y: True (zero-mean targets)
\end{itemize}

\subsubsection{Training Process}

\begin{enumerate}
\item Input: Historical time series [(t₁, y₁), (t₂, y₂), ..., (tₙ, yₙ)]
\item Compute Gram matrix K: K\_ij = k(tᵢ, tⱼ) for all observation pairs
\item Maximum likelihood estimation: Optimize kernel hyperparameters θ
\item Maximize log p(y | X, θ) = -½ yᵀK⁻¹y - ½ log|K| - n/2 log(2π)
\item Store learned kernel parameters
\end{enumerate}

\subsubsection{Prediction Process (Bayesian Inference)}

\begin{enumerate}
\item For new time t*: Compute k* = [k(t*, t₁), k(t*, t₂), ..., k(t*, tₙ)] Compute k** = k(t*, t*)
\item Posterior mean (prediction): μ(t*) = k*ᵀ K⁻¹ y
\item Posterior variance (uncertainty): σ²(t*) = k** - k*ᵀ K⁻¹ k*
\item 95\% confidence interval: [μ(t*) - 1.96σ(t*), μ(t*) + 1.96σ(t*)]
\end{enumerate}

\begin{itemize}
\item Compute k* = [k(t*, t₁), k(t*, t₂), ..., k(t*, tₙ)]
\item Compute k** = k(t*, t*)
\end{itemize}

\subsubsection{Model Performance}

\begin{itemize}
\item R² Score: 0.94 (94\% variance explained)
\item MAE (pH): 0.12 units
\item MAE (TDS): 15.3 ppm
\item MAE (Turbidity): 0.8 NTU
\item MAE (Temperature): 1.2°C
\item Calibration: 95\% of observations within 95\% CI
\end{itemize}

\subsubsection{Key Advantages}

\begin{itemize}
\item Uncertainty quantification (confidence intervals)
\item Non-linear trend capture
\item Automatic smoothness tuning
\item Works well with small datasets (>10 samples)
\end{itemize}

\subsection{Output Parameters}\label{section-5-3}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
forecast\_date & date & Date of prediction \\
\hline
predicted\_value & float & Point forecast \\
\hline
lower\_bound\_95 & float & 95\% confidence lower bound \\
\hline
upper\_bound\_95 & float & 95\% confidence upper bound \\
\hline
uncertainty & float & Standard error of prediction \\
\hline
prob\_exceed\_threshold & float & P(value > WHO threshold) \\
\hline
r2\_score & float & Model fit quality (0-1) \\
\hline
\end{longtable}

\subsection{Pseudocode}\label{section-5-4}

\section{Bayesian Cost Optimizer}\label{section-6}

Purpose: Optimize testing resource allocation across sites to maximize contamination detection within budget constraints.

Algorithm: Bayesian Optimization with Gaussian Process surrogate model and Expected Improvement acquisition function.

Objective: Find optimal testing schedule that maximizes detection\_rate while minimizing cost.

\subsection{How It Functions}\label{section-6-0}

\subsubsection{Why Bayesian Optimization?}

Finding optimal testing schedules across dozens of sites is a "black-box" optimization problem —evaluating each schedule requires expensive simulations of detection rates and costs, making brute-force search impractical (testing all combinations would require millions of evaluations). Bayesian Optimization excels by building a probabilistic model of the objective function, intelligently selecting which schedules to test next based on Expected Improvement, converging to near-optimal solutions in just 50 iterations instead of millions.

\subsubsection{How Expected Improvement Works in Simple Terms}

Expected Improvement (EI) balances exploration and exploitation like a smart treasure hunter. Current best schedule: ₹2.3M cost, 88\% detection rate. Should we try testing high-risk sites weekly (expensive but thorough) or reduce all sites to quarterly (cheap but risky)? EI computes: "Weekly high-risk testing has 40\% chance of improving detection to 92\% (big gain but uncertain), while quarterly reduction has 80\% chance of small 1\% improvement (safe but limited)." The optimizer picks the option with highest expected benefit, gradually learning which schedule patterns work best.

\subsubsection{Learning and Optimization Loop}

The optimizer starts by testing 10 random schedules to understand the landscape. Each evaluation simulates: "If we test Site A weekly (52×₹1000) and Site B monthly (12×₹1000), what's the combined detection rate?" After each test, a Gaussian Process model learns: "Weekly testing of high-risk coastal sites gives better detection-per-rupee than weekly testing low-risk inland sites." The acquisition function (EI) then suggests: "Next, try bi-weekly for medium-risk sites—high potential for cost savings." This cycle repeats for 50 iterations, converging to schedules achieving 35-40\% cost reduction while maintaining 85\%+ detection rates.

\subsubsection{Real-World Example}

Current baseline: All 50 sites tested monthly = 600 annual tests × ₹1,000 = ₹6,00,000/year. The optimizer discovers: "Critical sites (5) tested bi-weekly (130 tests), high-risk (15) monthly (180 tests), medium (20) bi-monthly (120 tests), low (10) quarterly (40 tests) = 470 total tests = ₹4,70,000 (22\% savings) with 86\% detection rate vs. baseline 84\%." It found this by learning that recent contamination history predicts future events better than geographic proximity.

\subsubsection{When Invoked}

This model runs quarterly during budget planning to optimize testing resource allocation across the entire site network based on updated risk assessments.

\subsection{Input Parameters}\label{section-6-1}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
sites & array & List of site objects with risk\_score \\
\hline
budget\_inr & float & Available annual budget in INR \\
\hline
cost\_per\_test & float & Estimated cost per water test (default: ₹1000) \\
\hline
\end{longtable}

\subsection{Machine Learning Algorithm Details}\label{section-6-2}

Implementation: Bayesian Optimization with sklearn.gaussian\_process.GaussianProcessRegressor

Problem Type: Black-box optimization (expensive-to-evaluate objective function)

\subsubsection{Search Space}

Optimize testing frequency for each site:

\begin{itemize}
\item Decision variables: tests\_per\_year for each of N sites
\item Domain: Each variable ∈ \{4, 6, 12, 26, 52\} (discrete choices: quarterly, bi-monthly, monthly, bi-weekly, weekly)
\item Dimensionality: N-dimensional optimization (one frequency per site)
\end{itemize}

\subsubsection{Objective Function}

Multi-objective optimization with scalarization:

\begin{itemize}
\item f(x) = α × detection\_rate(x) - β × normalized\_cost(x)
\item α = 0.7: Weight for detection rate maximization
\item β = 0.3: Weight for cost minimization
\item detection\_rate(x): Weighted average across sites (higher risk sites weighted more)
\item normalized\_cost(x): Total cost divided by budget
\item Goal: Maximize f(x) subject to total\_cost(x) ≤ budget
\end{itemize}

\subsubsection{Gaussian Process Surrogate Model}

\begin{itemize}
\item Kernel: Matérn(ν=2.5) - captures non-smooth objective landscape
\item Length scale: Auto-tuned via maximum likelihood estimation
\item Noise level: 0.01 (small noise due to deterministic simulation)
\item Purpose: Build probabilistic model of f(x) from observed evaluations
\end{itemize}

\subsubsection{Acquisition Function}

Expected Improvement (EI) with exploration-exploitation tradeoff:

\begin{itemize}
\item Formula: EI(x) = E[max(0, f(x) - f(x*)] where x* is current best
\item Interpretation: Expected improvement over current best solution
\item ξ parameter: 0.01 (exploration bonus)
\item Selection: x\_next = argmax EI(x) over candidate points
\end{itemize}

\subsubsection{Bayesian Optimization Loop}

\begin{enumerate}
\item Initialize: Evaluate 10 random schedules (Latin Hypercube Sampling)
\item Build GP: Fit Gaussian Process to observed \{(x₁, f(x₁)), ..., (xₙ, f(xₙ))\}
\item Acquisition: Find x\_next = argmax EI(x) using gradient-free optimization
\item Evaluate: Simulate schedule x\_next → compute detection\_rate and cost → get f(x\_next)
\item Update: Add (x\_next, f(x\_next)) to observations
\item Repeat: Steps 2-5 for 50 iterations or until convergence
\end{enumerate}

\subsubsection{Convergence Criteria}

\begin{itemize}
\item Maximum iterations: 50
\item Early stopping: If best f(x) doesn't improve by >0.01 for 10 consecutive iterations
\item Budget constraint: total\_cost(x\_best) ≤ budget\_inr
\end{itemize}

\subsubsection{Hyperparameters}

\begin{itemize}
\item n\_initial: 10 (random initialization points)
\item n\_iter: 50 (maximum optimization iterations)
\item kernel: Matérn(nu=2.5, length\_scale=1.0, length\_scale\_bounds=(1e-2, 1e2))
\item acquisition: Expected Improvement (EI)
\item xi: 0.01 (exploration parameter)
\item random\_state: 42 (for reproducibility)
\end{itemize}

\subsubsection{Key Advantages of Bayesian Optimization}

\begin{itemize}
\item Efficient for expensive black-box functions (each schedule simulation requires computing site-level detection rates)
\item Uncertainty quantification via GP posterior variance
\item Automatic exploration-exploitation balance
\item Global optimization (not stuck in local optima like gradient descent)
\item Works with discrete/mixed search spaces
\end{itemize}

\subsection{Output Parameters}\label{section-6-3}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
total\_current\_cost & float & Baseline annual cost (INR) \\
\hline
total\_optimized\_cost & float & Optimized annual cost (INR) \\
\hline
total\_savings & float & Annual savings (INR) \\
\hline
cost\_reduction\_percent & float & Percentage reduction \\
\hline
average\_detection\_rate & float & Expected contamination detection \% \\
\hline
\end{longtable}

\subsection{Pseudocode}\label{section-6-4}

\section{Real-time WQI Calculator (Rule-Based)}\label{section-7}

Purpose: Calculate Water Quality Index score for real-time assessment.

Algorithm Type: Rules-based penalty scoring system (not ML)

Standards: Aligned with WHO Guidelines for Drinking-water Quality and BIS 10500:2012

\subsection{Input Parameters}\label{section-7-1}

\begin{longtable}{|l|l|l|l|}
\hline
Parameter & Type & Unit & Optimal Range \\
\hline
ph & float & - & 6.5 - 8.5 \\
\hline
tds & float & ppm & < 500 \\
\hline
turbidity & float & NTU & < 5 \\
\hline
chlorine & float & mg/L & 0.2 - 5.0 \\
\hline
temperature & float & °C & 10 - 25 \\
\hline
\end{longtable}

\subsection{Internal Operations (Penalty Scoring)}\label{section-7-2}

\begin{enumerate}
\item Start with perfect score: WQI = 100
\item pH Penalty (max 20): If pH < 6.5: penalty = min(20, (6.5 - pH) × 10) If pH > 8.5: penalty = min(20, (pH - 8.5) × 10)
\item TDS Penalty (max 30): If TDS > 500: penalty = min(30, (TDS - 500) / 50)
\item Turbidity Penalty (max 20): If turbidity > 5: penalty = min(20, (turbidity - 5) × 2)
\item Chlorine Penalty (max 15): If chlorine < 0.2: penalty = 15; If chlorine > 5.0: penalty = 10
\item Temperature Penalty (max 10): If outside 10-25°C range
\item Final WQI = clamp(100 - sum(penalties), 0, 100)
\item Classify: Excellent (≥90), Compliant (≥70), Warning (≥50), Unsafe (<50)
\end{enumerate}

\begin{itemize}
\item If pH < 6.5: penalty = min(20, (6.5 - pH) × 10)
\item If pH > 8.5: penalty = min(20, (pH - 8.5) × 10)
\end{itemize}

\subsection{Output Parameters}\label{section-7-3}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
wqi\_score & float & 0-100 composite score \\
\hline
wqi\_class & string & "Excellent", "Compliant", "Warning", "Unsafe" \\
\hline
is\_drinkable & boolean & True if WQI ≥ 70 \\
\hline
ph\_penalty & float & pH contribution to score reduction \\
\hline
tds\_penalty & float & TDS contribution \\
\hline
turbidity\_penalty & float & Turbidity contribution \\
\hline
chlorine\_penalty & float & Chlorine contribution \\
\hline
temperature\_penalty & float & Temperature contribution \\
\hline
\end{longtable}

\subsection{Pseudocode}\label{section-7-4}

\section{Hybrid Anomaly Detection (Isolation Forest + CUSUM)}\label{section-8}

Purpose: Detect unusual sensor readings indicating equipment failure, contamination events, or data quality issues through two complementary approaches.

Algorithm: Hybrid system combining (1) Isolation Forest for sudden anomalies and (2) CUSUM (Cumulative Sum) for gradual drift detection.

Performance: 92\% accuracy with 12-minute average detection delay for residential monitoring (time from anomaly occurrence to alert delivery).

\begin{itemize}
\item Sampling interval: 15-minute readings (average 7.5 min wait for next measurement)
\item Edge processing: 42 milliseconds (on-device WQI calculation)
\item Cloud upload: 2.3 seconds (MQTT transmission)
\item Alert delivery: 1.8 seconds (SMS/push notification via SNS)
\item Total average delay: \textasciitilde 12 minutes (dominated by sampling interval)
\end{itemize}

\subsection{Part A: Isolation Forest - Sudden Anomaly Detection}\label{section-8-1}

Purpose: Detect sudden spikes or drops in water quality parameters (e.g., contamination events, sensor failures).

\subsubsection{Input Parameters}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
current\_reading & dict & Current sensor values \{ph, tds, turbidity, chlorine, temperature\} \\
\hline
historical\_stats & dict & Per-parameter statistics \{mean, std\} from historical data \\
\hline
\end{longtable}

\subsubsection{Machine Learning Algorithm Details}

Implementation: sklearn.ensemble.IsolationForest

Training Data: 15,000+ normal water quality samples (contamination-free baseline)

\subsubsection{Hyperparameters}

\begin{itemize}
\item n\_estimators: 100 isolation trees
\item contamination: 0.1 (expected 10\% anomaly rate)
\item max\_samples: 'auto' (256 samples per tree)
\item random\_state: 42 (for reproducibility)
\end{itemize}

\subsubsection{How Isolation Forest Works}

\begin{enumerate}
\item Tree Construction: Build 100 binary trees by randomly selecting: A feature (pH, TDS, turbidity, chlorine, or temperature) A split value between min and max of that feature
\item Path Length Calculation: For each sample: Traverse each tree until reaching a leaf node Count steps (path length) to isolation Anomalies isolate quickly (short paths) Normal samples require more splits (long paths)
\item Anomaly Score: Average path length across all 100 trees Score ∈ [0, 1] where higher = more anomalous Score > 0.5 typically indicates anomaly
\end{enumerate}

\begin{itemize}
\item A feature (pH, TDS, turbidity, chlorine, or temperature)
\item A split value between min and max of that feature
\end{itemize}

\begin{itemize}
\item Traverse each tree until reaching a leaf node
\item Count steps (path length) to isolation
\item Anomalies isolate quickly (short paths)
\item Normal samples require more splits (long paths)
\end{itemize}

\begin{itemize}
\item Score ∈ [0, 1] where higher = more anomalous
\item Score > 0.5 typically indicates anomaly
\end{itemize}

\subsubsection{Key Advantages}

\begin{itemize}
\item Unsupervised learning (no labeled anomalies needed)
\item Handles multivariate anomalies (unusual combinations of parameters)
\item Fast prediction (O(log n) per tree)
\item Robust to feature scaling differences
\end{itemize}

\subsubsection{Output Parameters}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
is\_anomaly & boolean & True if any parameter exceeds 3σ \\
\hline
anomaly\_type & string & "spike" or "drop" \\
\hline
anomaly\_score & float & 0-1 severity score \\
\hline
parameter & string & Most anomalous parameter \\
\hline
deviation\_sigma & float & Number of standard deviations \\
\hline
details & array & Per-parameter anomaly details \\
\hline
\end{longtable}

\subsubsection{Pseudocode - Isolation Forest}

\subsection{Part B: CUSUM - Gradual Drift Detection}\label{section-8-2}

Purpose: Detect gradual degradation or drift in water quality parameters over time (e.g., pipe corrosion, membrane degradation, infrastructure aging).

Method: CUSUM (Cumulative Sum Control Chart) tracks cumulative deviations from expected baseline to identify sustained shifts.

\subsubsection{Input Parameters}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
measurement\_sequence & array & Time-ordered sequence of sensor readings \\
\hline
baseline\_mean & float & Expected parameter value (from training period) \\
\hline
threshold & float & CUSUM threshold (default: 5σ) \\
\hline
drift\_magnitude & float & Minimum meaningful shift to detect (default: 0.5σ) \\
\hline
\end{longtable}

\subsubsection{Internal Operations - CUSUM Algorithm}

CUSUM maintains two cumulative sums to detect upward (S H ) and downward (S L ) shifts:

\begin{enumerate}
\item For each new measurement x (t) : Standardize: z (t) = (x (t) - μ) / σ Update upward CUSUM: S H (t) = max(0, S H (t-1) + z (t) - k) Update downward CUSUM: S L (t) = max(0, S L (t-1) - z (t) - k) Slack parameter k = 0.5 (half-sigma shift detection)
\item Drift detected if S H > threshold OR S L > threshold
\item Reset cumulative sums after drift detection and intervention
\end{enumerate}

\begin{itemize}
\item Standardize: z (t) = (x (t) - μ) / σ
\item Update upward CUSUM: S H (t) = max(0, S H (t-1) + z (t) - k)
\item Update downward CUSUM: S L (t) = max(0, S L (t-1) - z (t) - k)
\item Slack parameter k = 0.5 (half-sigma shift detection)
\end{itemize}

\subsubsection{Output Parameters}

\begin{longtable}{|l|l|l|}
\hline
Parameter & Type & Description \\
\hline
drift\_detected & boolean & True if gradual drift identified \\
\hline
drift\_direction & string & "upward" or "downward" \\
\hline
cusum\_value & float & Current cumulative sum magnitude \\
\hline
parameter & string & Parameter showing drift \\
\hline
drift\_start\_time & datetime & Estimated drift onset timestamp \\
\hline
\end{longtable}

\subsubsection{Pseudocode - CUSUM Drift Detection}

\subsection{Why Use TWO Detectors Together?}\label{section-8-0}

\subsubsection{Complementary Detection Capabilities}

Isolation Forest and CUSUM catch fundamentally different anomaly types . Imagine water quality as a patient's vital signs: Isolation Forest is like a smoke alarm that detects sudden heart attacks (spike: pH drops from 7.5 to 5.2 overnight due to contamination event), while CUSUM is like tracking gradual weight gain over months (drift: TDS slowly increasing from 380 to 510 ppm over 60 days due to pipe corrosion).

\subsubsection{Real-World Detection Examples}

Sudden Anomaly (Isolation Forest catches it): A sewage line ruptures near a municipal water tank. Coliform spikes from 0 to 45 MPN/100mL within 4 hours. Isolation Forest detects this immediately because the reading is far outside normal multivariate patterns (short path length in isolation trees), triggering emergency alerts.

Gradual Drift (CUSUM catches it): Membrane filters in a residential RO system slowly degrade over 90 days. TDS creeps from 380 → 420 → 465 → 510 ppm across weekly measurements. Each individual reading seems "normal-ish" so Isolation Forest doesn't trigger, but CUSUM accumulates these small deviations (cumulative sum exceeds threshold after 60 days), alerting operators to schedule filter replacement before TDS exceeds the 500 ppm safety limit.

\subsubsection{When Each Detector Activates}

Isolation Forest: Runs on every sensor reading (15-minute intervals for IoT sensors, per-test for LEGOLAS lab samples) to catch sudden contamination, sensor malfunctions, or data transmission errors.

CUSUM: Runs on time-series windows (trailing 30-90 days of data) to detect infrastructure aging, seasonal drift, or gradual source contamination that develops slowly enough to evade sudden anomaly detection.

\subsection{Hybrid Detection Strategy}\label{section-8-3}

The system runs both Isolation Forest and CUSUM concurrently:

\begin{itemize}
\item Isolation Forest: Triggers immediate alerts for sudden anomalies (contamination events, sensor failures)
\item CUSUM: Triggers maintenance alerts for gradual drift (pipe corrosion, membrane degradation)
\item Combined Performance: 92\% accuracy, 12-minute average detection delay for residential monitoring (time from anomaly occurrence until alert is sent to homeowner)
\item False Positive Rate: 8\% (filtered via confirmation logic requiring 2 consecutive detections)
\item Detection Delay Composition: Primarily limited by 15-minute sampling interval; actual computation and alert delivery occurs in under 5 seconds
\end{itemize}

\section{Complete ML Analysis Pipeline}\label{section-9}

The following pseudocode describes the complete end-to-end machine learning pipeline that runs when a new water sample is processed. This shows actual ML model operations including loading trained models, feature preprocessing, and ML inference:

\section{Intervention Management and Treatment Effectiveness}\label{section-10}

The Jal Sarovar system integrates an intervention management module that tracks water treatment actions,
        remediation efforts, and their effectiveness. This closed-loop system enables evidence-based decision-making
        by connecting contamination detection with treatment implementation and outcome measurement.

\subsection{Intervention Framework}\label{section-10-1}

When the ML pipeline detects water quality issues through contamination classification or anomaly detection,
        the system automatically suggests appropriate interventions based on:

\begin{itemize}
\item Contamination type: Different treatment methods for sewage ingress vs. salt intrusion vs. pipe corrosion
\item Severity level: Critical issues trigger immediate response protocols
\item Cost-effectiveness: Treatment recommendations balanced against available budget
\item Historical effectiveness: Past intervention success rates inform future recommendations
\end{itemize}

\subsection{Intervention Types}\label{section-10-2}

The system tracks eight categories of interventions:

\begin{longtable}{|l|l|l|}
\hline
Intervention Type & Description & Typical Applications \\
\hline
Water Treatment & Chemical or physical treatment processes & Coagulation, flocculation, sedimentation \\
\hline
Cleaning/Maintenance & Regular maintenance and cleaning operations & Tank cleaning, sediment removal, biofilm treatment \\
\hline
Infrastructure Repair & Structural repairs to water infrastructure & Leak repair, crack sealing, lining replacement \\
\hline
Equipment Replacement & Replacement of failed or degraded equipment & Pump replacement, valve upgrade, filter media change \\
\hline
Chlorination & Disinfection through chlorine addition & Break-point chlorination, continuous dosing, shock chlorination \\
\hline
Filtration & Physical removal of suspended particles & Sand filtration, membrane filtration, cartridge filters \\
\hline
UV/Chemical Disinfection & Non-chlorine disinfection methods & UV sterilization, ozone treatment, electrochlorination \\
\hline
Other & Custom or specialized interventions & Site-specific solutions, experimental treatments \\
\hline
\end{longtable}

\subsection{Effectiveness Measurement}\label{section-10-3}

Each completed intervention is evaluated using before-and-after water quality measurements.
        The system calculates improvement percentage based on the targeted parameter:

\subsection{Deployment Results}\label{section-10-4}

The intervention tracking system has recorded [DATA] simulated interventions
        across all monitored sites, with [DATA] completed simulated interventions
        providing measurable outcome data for framework validation.

\begin{longtable}{|l|l|l|}
\hline
Metric & Value & Description \\
\hline
Total Simulated Interventions & [DATA] & All simulated interventions across all sites (planned, in-progress, completed) - for reference \\
\hline
Completed Simulated Interventions & [DATA] & Simulated interventions with verified completion and outcome data - for reference \\
\hline
Average Effectiveness (Simulated) & [DATA]\% & Mean improvement in targeted water quality parameter (simulated scenarios) \\
\hline
Total Simulated Investment & Rs. \{\{ '\{:,.0f\}'.format(stats.total\_intervention\_cost) \}\} & Cumulative cost of all simulated interventions with recorded expenses - for reference \\
\hline
\end{longtable}

\subsection{Integration with ML Pipeline}\label{section-10-5}

The intervention module integrates with the ML pipeline through automated treatment recommendations:

This integration ensures that ML-based contamination detection directly informs actionable remediation strategies,
        creating a data-driven feedback loop that continuously improves water quality management.

\section{Results Summary}\label{section-11}

\subsection{Model Performance Metrics}\label{section-11-1}

\begin{longtable}{|l|l|l|l|}
\hline
Model & Metric & Value & Reference Target \\
\hline
Site Risk Classifier & Predictions & [RISK\_PRED] & - \\
\hline
Contamination Classifier & Avg Confidence & [DATA]\% & 82\% F1 \\
\hline
Water Quality Forecaster & R² Score & [DATA] & 0.76-0.81 \\
\hline
Cost Optimizer & Cost Reduction & [COST\textbackslash \_REDUCTION]\% & 62\% \\
\hline
Cost Optimizer & Detection Rate & [DATA]\% & >90\% \\
\hline
WQI Calculator & Average WQI & [DATA] & - \\
\hline
\end{longtable}

\subsection{Geographic Coverage}\label{section-11-2}

\begin{longtable}{|l|l|l|}
\hline
State & Sites & Samples \\
\hline
[DATA] & [DATA] & [DATA] \\
\hline
\end{longtable}

\section{Conclusion and Future Work}\label{section-12}

\subsection{Implementation Roadmap}\label{section-12-1}

{\small
\begin{longtable}{|p{2.5cm}|p{1.8cm}|p{3.5cm}|p{4cm}|p{2cm}|}
\hline
\textbf{Phase} & \textbf{Status} & \textbf{Key Objectives} & \textbf{Key Achievements / Milestones} & \textbf{Timeline} \\
\hline
Phase 1 Preliminary Trials & COMPLETED & • LEGOLAS robotic platform proof-of-concept • IoT sensor preliminary trials • Bulk data import infrastructure setup & • [TOTAL\textbackslash \_SITES] public sites onboarded • Baseline dataset: [TOTAL\textbackslash \_SAMPLES] samples • Data standardization pipeline validated & Completed [DATA] \\
\hline
Phase 2 ML Development & COMPLETED & • Train and validate 5 ML models • Performance optimization and validation • Production deployment readiness & • 84.6\% risk prediction accuracy • 73.4\% contamination classification • R²=0.94 forecasting performance • [COST\textbackslash \_REDUCTION]\% cost reduction & Completed [DATA] \\
\hline
Phase 3 Ramp-Up Deployment & IN PROGRESS & • Expand LEGOLAS to 10-15 additional sites • Deploy IoT to 25-50 residential systems • Real-time ML model integration • Sensor accuracy validation vs. laboratory & • Deployment expansion underway • Real-time data pipeline integration • Cross-validation framework operational & Current [DATA] \\
\hline
Phase 4 Scale-Up LEGOLAS & PLANNED & • Deploy to 50+ public water bodies • Multi-state geographic expansion • Navigation algorithm optimization • Automated maintenance protocols & Target Specifications: • Fiberglass hull with GPS navigation • 6-sensor suite + computer vision • Cost: ₹2.7L per unit • 14-day autonomous operation & Next 12-18 months \\
\hline
Phase 5 Scale-Up IoT & PLANNED & • Deploy to 500+ residential water systems • Edge computing optimization • User-facing mobile app development • Automated sensor health monitoring & Target Specifications: • Edge computing: Raspberry Pi • Connectivity: LoRaWAN/NB-IoT • Cost: ₹8,000-15,000 per household • Sampling: 15-minute intervals & 18-24 months \\
\hline
Phase 6 Hybrid Operations & ONGOING & • Permanent coexistence of manual and autonomous data • Multi-source data fusion (laboratory > LEGOLAS > IoT) • Automated anomaly → manual verification loops • Expert review of critical ML predictions & • Hybrid model operational • Data reliability weighting implemented • Human oversight protocols established • Government integration active & Long-term operational mode \\
\hline
\end{longtable}
}

Key Insight: The transition to autonomous operation is incremental, not revolutionary .
        Manual data collection established the intelligent foundation through bulk imports and laboratory validation (Phases 1-2).
        Autonomous systems enhance monitoring coverage and frequency (Phases 3-5), while human expertise and laboratory validation
        remain essential for water safety decisions (Phase 6 ongoing). This hybrid approach balances technological innovation
        with public health responsibility.

\subsection{Current Achievements (Phases 1-2 Complete)}

The Jal Sarovar framework has successfully completed foundational development and validation phases:

\begin{itemize}
\item Data Infrastructure: Established comprehensive dataset of [TOTAL\textbackslash \_SAMPLES] water quality
            samples from [TOTAL\textbackslash \_SITES] public monitoring sites, spanning [DATE\textbackslash \_RANGE] years of
            historical data through bulk imports (CSV, API, manual entry)
\item ML Model Validation: Five production-ready models achieve [DATA]\% risk
            prediction accuracy, [DATA]\% contamination classification, and R²=[DATA]
            forecasting performance on historical data
\item Proof-of-Concept Deployment: LEGOLAS robotic platform and IoT sensor preliminary trials successfully
            validated autonomous data collection capabilities and sensor accuracy against laboratory standards
\item Cost Optimization: Demonstrated [COST\textbackslash \_REDUCTION]\% potential reduction in testing costs
            through intelligent resource allocation while maintaining [DATA]\% contamination detection rate
\item Government Integration: Framework aligned with Mission Amrit Sarovar (68,000+ national water bodies),
            Jal Jeevan Mission (rural drinking water), and state/municipal monitoring programs
\end{itemize}

\subsection{Future Work and Scaling Strategy (Phases 3-6)}

The roadmap focuses on incremental scaling of autonomous monitoring infrastructure while
        maintaining the hybrid data collection model:

\subsubsection{Near-Term: Phase 3 Ramp-Up (Current Focus)}

\begin{itemize}
\item Expand LEGOLAS deployment to 10-15 additional public water body sites with real-time ML integration for
            site risk assessment and contamination detection
\item Deploy IoT sensors to 25-50 additional residential water systems with real-time anomaly detection and
            alert notifications
\item Continue bulk import focus as primary data source while validating autonomous sensor accuracy through
            cross-validation against laboratory test results
\item Integrate LEGOLAS and IoT sensor data streams with Phase 2 production ML models for real-time predictions
\end{itemize}

\subsubsection{Mid-Term: Phases 4-5 Scale-Up (12-24 Months)}

\begin{itemize}
\item LEGOLAS Expansion: Deploy to 50+ public water bodies across Gujarat, Maharashtra, and additional
            states with optimized navigation algorithms for diverse water body types (stepwells, tanks, ponds, lakes, rivers)
\item IoT Network Growth: Expand inline sensor network to 500+ residential water systems with edge
            computing optimization, user-facing mobile app for real-time alerts, and automated sensor health monitoring
\item Integration Strategy: Autonomous data streams supplement, not replace, manual laboratory
            testing—preserving accuracy standards while increasing monitoring frequency and geographic coverage
\end{itemize}

\subsubsection{Long-Term: Phase 6 Hybrid Operational Model (Permanent)}

\begin{itemize}
\item Data Source Coexistence: Manual import channels (CSV uploads, API integration, laboratory submissions)
            continue alongside autonomous streams (LEGOLAS robots, IoT sensors, third-party smart meters)
\item Data Fusion Framework: ML models weight multi-source data by reliability hierarchy:
            Laboratory > LEGOLAS > IoT > Field Kits, ensuring critical decisions prioritize highest-quality data
\item Human-AI Collaboration: Automated anomaly detection triggers manual verification sampling;
            expert review required for critical predictions; laboratory validation remains gold standard
\item Government Scalability: Framework designed to support Mission Amrit Sarovar's 68,000+ water body
            target and Jal Jeevan Mission's rural household coverage through cost-effective hybrid monitoring
\end{itemize}

\section{References}\label{section-13}

\begin{enumerate}
\item World Health Organization, "Progress on household drinking water, sanitation and hygiene 2000-2017:
                Special focus on inequalities," WHO/UNICEF Joint Monitoring Programme, 2019.
\item Central Pollution Control Board (CPCB), "Status of Water Quality in India - 2020,"
                Ministry of Environment, Forest and Climate Change, Government of India, 2020.
\item World Health Organization, "Guidelines for drinking-water quality: fourth edition incorporating
                the first addendum," Geneva: World Health Organization, 2017.
\item Bureau of Indian Standards, "IS 10500:2012 Drinking Water - Specification (Second Revision),"
                BIS, New Delhi, 2012.
\item T. P. Lambrou, C. C. Anastasiou, C. G. Panayiotou, and M. M. Polycarpou, "A low-cost sensor network
                for real-time monitoring and contamination detection in drinking water distribution systems," IEEE Sensors Journal , vol. 14, no. 8, pp. 2765-2772, 2014.
\item S. Geetha and S. Gouthami, "Internet of things enabled real time water quality monitoring system," Smart Water , vol. 2, no. 1, pp. 1-19, 2016.
\item J. Manley and S. Willcox, "The Wave Glider: A persistent platform for ocean science,"
                in Proc. IEEE OCEANS Conf. , 2010, pp. 1-5.
\item M. Dunbabin and L. Marques, "Robots for environmental monitoring: Significant advancements and applications," IEEE Robotics \& Automation Magazine , vol. 19, no. 1, pp. 24-39, 2012.
\item K. Chen et al., "Comparative analysis of surface water quality prediction performance and identification
                of key water parameters using different machine learning models based on big data," Water Research , vol. 171, p. 115454, 2020.
\item A. Kulkarni, D. Mukherjee, and K. N. Sharma, "Water quality classification using machine learning," Int. J. Eng. Res. Technol. , vol. 10, no. 3, pp. 581-585, 2021.
\item Y. Zhang, P. Gao, Y. Li, and X. Fang, "A machine learning based approach to identify protected area
                management effectiveness," Sustainability , vol. 11, no. 13, p. 3690, 2019.
\item U. Ahmed et al., "Prediction of drinking water quality using machine learning,"
                in Proc. IEEE Int. Conf. Commun. Signal Process. Appl. , 2019, pp. 1-5.
\item H. Wang, H. Hu, H. Li, and B. Li, "Water quality prediction based on long short-term memory neural network,"
                in Proc. Int. Conf. Water Resources Environ. , 2021, pp. 234-241.
\item S. Seo et al., "Automated plankton classification with a mask-convolutional neural network," Applied Sciences , vol. 11, no. 9, p. 4332, 2021.
\item M. H. Gholizadeh, A. M. Melesse, and L. Reddi, "A comprehensive review on water quality parameters
                estimation using remote sensing techniques," Sensors , vol. 16, no. 8, p. 1298, 2016.
\item L. Breiman, "Random forests," Machine Learning , vol. 45, no. 1, pp. 5-32, 2001.
\item T. Chen and C. Guestrin, "XGBoost: A scalable tree boosting system,"
                in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining , 2016, pp. 785-794.
\item S. M. Lundberg and S.-I. Lee, "A unified approach to interpreting model predictions,"
                in Advances in Neural Information Processing Systems , 2017, pp. 4765-4774.
\item C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for Machine Learning .
                Cambridge, MA: MIT Press, 2006.
\item J. Snoek, H. Larochelle, and R. P. Adams, "Practical Bayesian optimization of machine learning algorithms,"
                in Advances in Neural Information Processing Systems , 2012, pp. 2951-2959.
\item F. T. Liu, K. M. Ting, and Z.-H. Zhou, "Isolation forest,"
                in Proc. IEEE Int. Conf. Data Mining , 2008, pp. 413-422.
\item E. S. Page, "Continuous inspection schemes," Biometrika , vol. 41, no. 1/2, pp. 100-115, 1954.
\item M. Sandler et al., "MobileNetV2: Inverted residuals and linear bottlenecks,"
                in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2018, pp. 4510-4520.
\end{enumerate}

\end{document}
